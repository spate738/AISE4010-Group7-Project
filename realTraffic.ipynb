{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9a42d3e"
      },
      "source": [
        "## AISE4010- Project - Traffic Congestion\n",
        "\n",
        "### Group 7:\n",
        "#### Aaron Triguero, Khen Agnes, Shiv Pi Patel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, Normalization\n",
        "from keras.layers import LSTM, SimpleRNN, Conv1D, GRU\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "i7RTsIlzuHT2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View raw files for speed, occupancy, travel time"
      ],
      "metadata": {
        "id": "bRBrPDeqRWGe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "WXLQRQBZuEXv",
        "outputId": "c2749830-7df6-401a-c10e-440cbc07b47c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'occupancy_6005.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-19457ced2190>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load Occupancy dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_o1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'occupancy_6005.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Occupancy'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_o2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'occupancy_t4013.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Occupancy'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Set index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'occupancy_6005.csv'"
          ]
        }
      ],
      "source": [
        "# Load Occupancy dataset\n",
        "df_o1 = pd.read_csv('occupancy_6005.csv').rename(columns={'value':'Occupancy'})\n",
        "df_o2 = pd.read_csv('occupancy_t4013.csv').rename(columns={'value':'Occupancy'})\n",
        "\n",
        "# Set index\n",
        "df_o1['timestamp'] = pd.to_datetime(df_o1['timestamp'])   # to datetime\n",
        "df_o2['timestamp'] = pd.to_datetime(df_o2['timestamp'])\n",
        "df_o1 = df_o1.set_index('timestamp')\n",
        "df_o2 = df_o2.set_index('timestamp')\n",
        "print(df_o2.head())\n",
        "\n",
        "# plot\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(2, 1, 1)\n",
        "df_o1['Occupancy'].plot(ylabel='average # cars',title='Occupancy')\n",
        "plt.subplot(2, 1, 2)\n",
        "df_o2['Occupancy'].plot(ylabel='average # cars')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TravelTime dataset\n",
        "df_t1 = pd.read_csv('TravelTime_387.csv').rename(columns={'value':'Travel Time'})\n",
        "df_t2 = pd.read_csv('TravelTime_451.csv').rename(columns={'value':'Travel Time'})\n",
        "\n",
        "# Set index\n",
        "df_t1['timestamp'] = pd.to_datetime(df_t1['timestamp'])   # to datetime\n",
        "df_t2['timestamp'] = pd.to_datetime(df_t2['timestamp'])\n",
        "df_t1 = df_t1.set_index('timestamp')\n",
        "df_t2 = df_t2.set_index('timestamp')\n",
        "print(df_t2.head())\n",
        "\n",
        "# plot\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(2, 1, 1)\n",
        "df_t1['Travel Time'].plot(ylabel='seconds',title='Travel Time')\n",
        "plt.subplot(2, 1, 2)\n",
        "df_t2['Travel Time'].plot(ylabel='seconds')"
      ],
      "metadata": {
        "id": "4Iu9QkzowqWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load speed dataset\n",
        "df_s1 = pd.read_csv('speed_6005.csv').rename(columns={'value':'Speed'})\n",
        "df_s2 = pd.read_csv('speed_t4013.csv').rename(columns={'value':'Speed'})\n",
        "df_s3 = pd.read_csv('speed_7578.csv').rename(columns={'value':'Speed'})\n",
        "\n",
        "# Set index\n",
        "df_s1['timestamp'] = pd.to_datetime(df_s1['timestamp'])   # to datetime\n",
        "df_s2['timestamp'] = pd.to_datetime(df_s2['timestamp'])\n",
        "df_s3['timestamp'] = pd.to_datetime(df_s3['timestamp'])\n",
        "df_s1 = df_s1.set_index('timestamp')\n",
        "df_s2 = df_s2.set_index('timestamp')\n",
        "df_s3 = df_s3.set_index('timestamp')\n",
        "print(df_s2.head())\n",
        "\n",
        "# plot\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(3, 1, 1)\n",
        "df_s1['Speed'].plot(ylabel='km/h',title='Speed')\n",
        "plt.subplot(3, 1, 2)\n",
        "df_s2['Speed'].plot(ylabel='km/h')\n",
        "plt.subplot(3, 1, 3)\n",
        "df_s3['Speed'].plot(ylabel='km/h')"
      ],
      "metadata": {
        "id": "juZvFDAGxRm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Form Dataset and Preprocess\n",
        "\n",
        "- notice preprocess choices made, such as resampling"
      ],
      "metadata": {
        "id": "-C5GuJhzLVfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Joining, Resampling and Normalizing"
      ],
      "metadata": {
        "id": "gRCmOS0WcF6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset for intersection 6005\n",
        "# data_6005 = df_o1.join(df_t1, how='outer').join(df_s1, how='outer')\n",
        "# data_6005 = data_6005['2015-09-09':]  # take only data after certain date             # if we wanted to do 2 intersections\n",
        "\n",
        "# Dataset for intersection t4013\n",
        "data_t4013 = df_o2.join(df_t2, how='outer').join(df_s2, how='outer')\n",
        "data = data_t4013['2015-09-09':]  # take only data after certain date\n",
        "\n",
        "\n",
        "\n",
        "# Plot data before resampling\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(2,1,1)\n",
        "data['Speed'].plot(title='Intersection_t4013, before and after preprocess')#, ylabel='(different for each variable)')\n",
        "data['Occupancy'].plot()\n",
        "data['Travel Time'].plot()\n",
        "\n",
        "\n",
        "# Data after resampling (using mean) to 5 min intervals\n",
        "# and handling missing data using _______(interpolation)________\n",
        "data = data.resample('5min').mean()\n",
        "data = data.interpolate()\n",
        "\n",
        "# Normalize each variable using ________(MinMax)_________\n",
        "scaler = MinMaxScaler()\n",
        "data['Speed'] = scaler.fit_transform(data[['Speed']])\n",
        "data['Occupancy'] = scaler.fit_transform(data[['Occupancy']])\n",
        "data['Travel Time'] = scaler.fit_transform(data[['Travel Time']])\n",
        "\n",
        "\n",
        "# Plot data after preprocessing\n",
        "plt.subplot(2,1,2)\n",
        "data['Speed'].plot()#ylabel='(different for each variable)')\n",
        "data['Occupancy'].plot()\n",
        "data['Travel Time'].plot()\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "96GACj9GH1Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape    # (2510 timesteps, 3 variables)"
      ],
      "metadata": {
        "id": "K9u2NSIIdYl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Components of the time series"
      ],
      "metadata": {
        "id": "ptrf5_8Ych-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check seasonality, trends, etc for each variable"
      ],
      "metadata": {
        "id": "YlAn5hqZchlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting train and test sets"
      ],
      "metadata": {
        "id": "lgPEo6HscONu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sliding window to split data\n",
        "\n",
        "def sliding_window(data, n):\n",
        "    # data: original data\n",
        "    # n: window size\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - n):\n",
        "        X.append(data[i:(i + n)])\n",
        "        y.append(data[i + n])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "# For n timesteps\n",
        "n_steps = 12      # each 60 minutes (5 minutes per timestep)\n",
        "\n",
        "# Each variable\n",
        "Xo, yo = sliding_window(data['Occupancy'], n_steps)\n",
        "Xs, ys = sliding_window(data['Speed'], n_steps)\n",
        "Xt, yt = sliding_window(data['Travel Time'], n_steps)\n",
        "\n",
        "# Split data into training testing sets\n",
        "split = int(len(Xo)*0.8)\n",
        "\n",
        "Xo_train, Xo_test = Xo[:split], Xo[split:]\n",
        "yo_train, yo_test = yo[:split], yo[split:]\n",
        "\n",
        "Xs_train, Xs_test = Xs[:split], Xs[split:]\n",
        "ys_train, ys_test = ys[:split], ys[split:]\n",
        "\n",
        "Xt_train, Xt_test = Xt[:split], Xt[split:]\n",
        "yt_train, yt_test = yt[:split], yt[split:]\n",
        "\n",
        "# Reshape\n",
        "Xo_train = Xo_train.reshape(Xo_train.shape[0], Xo_train.shape[1], 1)\n",
        "Xo_test = Xo_test.reshape(Xo_test.shape[0], Xo_test.shape[1], 1)\n",
        "\n",
        "Xs_train = Xs_train.reshape(Xs_train.shape[0], Xs_train.shape[1], 1)\n",
        "Xs_test = Xs_test.reshape(Xs_test.shape[0], Xs_test.shape[1], 1)\n",
        "\n",
        "Xt_train = Xt_train.reshape(Xt_train.shape[0], Xt_train.shape[1], 1)\n",
        "Xt_test = Xt_test.reshape(Xt_test.shape[0], Xt_test.shape[1], 1)\n"
      ],
      "metadata": {
        "id": "ISMDXdP_cEcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Models, Training"
      ],
      "metadata": {
        "id": "3VMYIQDQenlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, Normalization\n",
        "from keras.layers import LSTM, SimpleRNN, Conv1D, GRU\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from time import time"
      ],
      "metadata": {
        "id": "i7f1FaQ6Bypb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Model"
      ],
      "metadata": {
        "id": "P80CClEeey1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create models\n",
        "# CNN model\n",
        "model_CNN = Sequential([\n",
        "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(Xo_train.shape[1], 1)),\n",
        "    Conv1D(32, kernel_size=3, activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Optimizer ________ and loss _________\n",
        "model_CNN.compile(optimizer='adam', loss='mean_squared_error')    # why?\n",
        "\n",
        "model_CNN_s, model_CNN_o, model_CNN_t= model_CNN, model_CNN, model_CNN\n",
        "\n",
        "# Choose parameters and train dataset\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "\n"
      ],
      "metadata": {
        "id": "L9yMUYIVe8PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training using CNN models"
      ],
      "metadata": {
        "id": "y2CtDTnWb-kU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Speed data\n",
        "start_time = time()\n",
        "cnn_history_speed = model_CNN_s.fit(Xs_train, ys_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2)\n",
        "cnn_time_speed = time() - start_time\n"
      ],
      "metadata": {
        "id": "iOFSIIjPb8Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Occupancy data\n",
        "start_time = time()\n",
        "cnn_history_occupancy = model_CNN_o.fit(Xo_train, yo_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2)\n",
        "cnn_time_occupancy = time() - start_time\n"
      ],
      "metadata": {
        "id": "VTb1a_NfcISu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Travel Time data\n",
        "start_time = time()\n",
        "cnn_history_ttime = model_CNN_t.fit(Xt_train, yt_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2)\n",
        "cnn_time_ttime = time() - start_time\n"
      ],
      "metadata": {
        "id": "zuGiwwFTVKb6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}